<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-1CMWXLFBCG"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-1CMWXLFBCG');
    </script>

    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ALIGNMENT 5: COULD AI HELP?</title>
<link rel="icon" href="favicon.ico" type="image/x-icon">
    <link rel="canonical" href="https://nonzerosum.games/alignment5.html" />
    <meta name="description" content="Exploring the alignment of individual and collective interests in the realm of politics and society.">
    <meta name="keywords" content="Centrism, UBI, Politics, Non-Zero-Sum, Aristotle, Richard Nixon, John Key, Ibram X Kendi, J.S Mill">
    <meta name="robots" content="index, follow">
    <meta name="author" content="NonZeroSumJames">

    <!-- For Facebook and LinkedIn -->
    <meta property="og:image" content="https://nonzerosum.games/Images/Social/alignment5.png">
    <meta property="og:title" content="ALIGNING INDIVIDUAL AND COLLECTIVE INTERESTS">
    <meta property="og:description" content="~ Aligning the Dichotomy ~">

    <!-- For Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@NonZeroSumJames">
    <meta name="twitter:image" content="https://nonzerosum.games/Images/Social/alignment5.png">
    <meta name="twitter:title" content="ALIGNING INDIVIDUAL AND COLLECTIVE INTERESTS">
    <meta name="twitter:description" content="~ Aligning the Dichotomy ~">

    <link rel="stylesheet" type="text/css" href="style.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
</head>

<body>
    <!-- Linking to Menu.html -->
    <script>
        $(document).ready(function() {
            $("#menu").load("menu.html", function() {
                var pageName = window.location.pathname.split("/").pop();
                var menuLink = $("a[href='" + pageName + "']");
                menuLink.parent().remove();
            });
        });
    </script>
    <div id="menu"></div>

    <!-- Content -->
    <h1 style="margin-bottom: 0;">COULD AI HELP?</h1>
    <aside>E</aside>
    <h2>the alignment problem no one is talking about: part 5</h2>

    <p><img src="./Images/Content/Alignment_HumanitysPlan.png" alt="Humanity's plan..."></p>

    <p>We began this series with Bryan Johnson's challenge that...</p>
    
    <blockquote>
    <p>"We need a plan, and we don't have a plan"—<b>Bryan Johnson</b></p>
    </blockquote>
    
    <p>Johnson is right, but as we have explored so far, throughout history, leaders from Aristotle to Ibram X. Kendi have found ways to get aligned on a positive trajectory.</p>
    
    <p>From the edict of "an eye for an eye" in the Code of Hammurabi to the Analects of Confucius and the first instance of the Golden rule to the Ten Commandments, The Magna Carta, and eventually the 30 articles of the Universal Declaration of Human Rights, humans have attempted to codify the shared values of civilisation.</p>
    
    <p><img src="./Images/Content/Alignment_VennDiagram.png" alt="a venn diagram with tablets and ethical documents in each circle, where they overlap it says 'Be nice'"></p>
    
    <p>While there are commonalities between these documents, it is clear that ethical frameworks evolve over time. So, pinning down an objective rule book for humanity's values may not be humanly possible. As discussed, we have biological limitations that mean we may not be well suited to dealing with alignment in a rapidly transforming and globalised digital era.</p>
    
    <p>It's important to note at this point, from the perspective of AI risk, that if we've learned anything from science fiction, hard and fast rules can be a liability when aligning goals. Issac Asimov's Three Laws of Robotics are intended to be foolproof.</p>
    
    <blockquote>
    <ul>
        <li><strong>First Law</strong>: A robot may not injure a human being, or, through inaction, allow a human being to come to harm.</li>
        <li><strong>Second Law</strong>: A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.</li>
        <li><strong>Third Law</strong>: A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.</li>
    </ul>
</blockquote>
    
    <p>Never-the-less Asimov's stories explore the many possible loopholes, demonstrating how difficult it would be to control AI with a set of rules. Even these three rules evolved, with the addition of the...</p>
    
    <blockquote>
    <ul>
        <li><strong>Zeroth Law</strong>: A robot may not harm humanity, or, by inaction, allow humanity to come to harm.</li>
    </ul>
</blockquote>
    
    <p>So, finding an objective rule set is problematic regarding the shared values of humanity and AI risk. So, is there another option?</p>
    
    <p><img src="./Images/Content/Alignment_AntSymbols.png" alt="The ants forming different value symbols"></p>
    
    <p>As we have alluded to in previous parts, humans face political and biological limitations that AI does not. So, could AI itself be the answer to alignment problems? Could it solve our misalignment between the individual and the collective, and could we design it in such a way that it can safe-guard itself from the AI alignment problem. I say yes.</p>
    
    <h3>AUGMENTING INDIVIDUAL BIASES</h3>
    
    <p>First of all, in "We need to talk about AI" Bryan Johnson suggests that AI could be designed as a tool to help alert us to our own biases and blind-spots, helping us become clearer thinkers. Clearer thinking would help individuals from getting in their own way, chasing bad decisions or getting into unnecessary conflicts, and this would in turn help the collective, leading to more productive dialogue and collaboration.</p>
    
    <p><img src="./Images/Content/Alignment_Shots.png" alt="a rabbit sitting in front of a line of shot glasses each named a different vice"></p>
    
    <p>Personally I use ChatGPT like this already, to test my assumptions, to point out holes in my argument and to play devil's advocate. AI in the form of the current Large Language Models (LLMs) is already remarkably reasonable and objective in its ability to evaluate ideas and offer constructive feedback, more so I would have to say than many humans... and this is only getting more refined.</p>
    
    <p>Perhaps it is my liberal bias but it seems to me that ChatGPT has some form of generative ethical framework already; for instance, when my daughter asked for an advert describing the benefits of hair-dye for dogs, Chat replied that it couldn't do so, because hair dye is not beneficial for dogs, and in fact can be harmful. This was surely not a hard-coded ethical position on pet cosmetics (it was just too random), it must have been generated through an understanding of higher order ethical considerations like truth claims and physical harm.</p>
    
    <h3>AUGMENTING COLLECTIVE ALIGNMENT</h3>
    
    <p>Secondly, if AI were to be given a general principle to increase alignment across humanity, it might be able to provide information that allows people to see the collective implications of their actions. So, not only would it help us make better decisions for ourselves, but also for the collective. It would also be able to find non-zero-sum games in this respect, pointing to actions that are selfishly beneficial and selflessly beneficial—guilt-free benefits!</p>
    
    <p>This would be a form of feedback that humans are presently missing. It can be difficult and time-consuming to investigate the origins of a product, or the validity of a statement online, or the efficacy of an action like giving to charity, boycotting a product or buying environmentally friendly goods. Having an unbiased source of information that can factor in many variables can mean that our actions in the world can be better augmented by accurate feedback. We still get to make the decision, just with a better understanding of the consequences.</p>
    
    <p><img src="./Images/Content/Alignment_MolochRobotGround.png" alt="A Moloch robot climbing out of a crack in the ground"></p>
    
    <h3>AUGMENTING AI ALIGNMENT</h3>
    
    <p>Finally, Artificial Intelligence, in the form of present day LLMs can already demonstrate a clear understanding of the AI Alignment Problem. It can also appreciate the fact that humanity's values are somewhat plastic, and evolve over time. An AI trained on a dataset that grows to reflect humanity, and one experienced in aligning humanity's interests, would be in an ideal position to maintain alignment between itself and us. So, rather than having a set of rules to follow, if an AI's main priority was to maintain the alignment between itself and humanity it could adapt to any alignment drift instantly.</p>
    
    <h3>SO...</h3>
    
    <p>Let's just let AI sort it out, right? Not quite. There are many risks still posed by AI to our civilisation, even existential risks. But I think enrolling AI's own resources to jointly work towards alignment seems like a sensible approach. This isn't as easy as hard-coding a "Law" to always maximise alignment, but more a <em>focus</em> of a continual dialogue. This approach mitigates the issue of the evolving nature of humanity's values, it avoids the loop-holes inherent in a rule-based system, and it hopefully helps humanity along the way.</p>
    
    <p><img src="./Images/Content/Alignment_RabbitRobot.png" alt="the rabbit and robot sitting next to each other on a motorbike"></p>
    
    <p>In the final part of this series we will look back over a series through which I have tried to provide more solutions than I have problems. While not a panacea to the humanity's woes, I hope that summarising the solutions we've explored will leave you feeling hopeful about our future together.</p>

    <div class="nav-section">
        <a href="alignment1.html" class="nav-link first"><b>|<</b></a>
        <a href="alignment4.html" class="nav-link prev"><b><<</b></a>
        <span class="part-number"><b>next:<br>SOLUTIONS</b></span>
        <a href="alignment6.html" class="nav-link last"><b>>|</b></a>
    </div>
    

    <footer>
        <div id="social-icons"></div>
        <h3>RELATED CONTENT</h3>
        <p>
            <ul>
                <li><a href="https://www.bryanjohnson.co/">Bryan Johnson</a> was a subject in the documentary <a href="https://www.youtube.com/watch?v=oqpvAIzW9KI">WE NEED TO TALK ABOUT AI</a>. He now does some pretty wild experiments on himself in the pursuit of life extension.</li>
            </ul>
        </p>
    </footer>

    <canvas></canvas>
    <div class="subscribe">
        <a href="subscribe.html" title="SUBSCRIBE" style="text-decoration: none;">8</a>
    </div>
    <script src="./js/alignment.js"></script>
    <div id="giscus_thread"></div>
    <script src="https://giscus.app/client.js"
            data-repo="jamesstephenbrown/nonzerosumgames"
            data-repo-id="MDEwOlJlcG9zaXRvcnkyNDUwNDE4Nzk="
            data-category-id="DIC_kwDODpsK184CA9jn"
            data-mapping="pathname"
            data-reactions-enabled="1"
            data-emit-metadata="0"
            data-input-position="bottom"
            data-theme="dark_dimmed"
            data-lang="en"
            crossorigin="anonymous"
            async>
    </script>
    <script>
        $(document).ready(function() {
            $("#social-icons").load("social.html", function() {
                // Get the current page URL and title
                var pageUrl = window.location.href;
                var pageTitle = document.title;

                // Replace placeholders in the loaded HTML
                $(this).find("a").each(function() {
                    this.href = this.href.replace('URL_PLACEHOLDER', encodeURIComponent(pageUrl));
                    this.href = this.href.replace('TITLE_PLACEHOLDER', encodeURIComponent(pageTitle));
                });
            });
        });
    </script>

    <div id="graphcomment"></div>
    <script type="text/javascript">
      /* - - - CONFIGURATION VARIABLES - - - */
      var __semio__params = {
        graphcommentId: "Non-Zero-Sum-Games", // Make sure the id is yours
        behaviour: {
          // Extract the filename from the URL path and use it as the UID
          uid: window.location.pathname.split('/').pop().split('.')[0],
        },
        // Configure your variables here
      }
      /* - - - DON'T EDIT BELOW THIS LINE - - - */
      function __semio__onload() {
        __semio__gc_graphlogin(__semio__params)
      }
      (function() {
        var gc = document.createElement('script'); gc.type = 'text/javascript'; gc.async = true;
        gc.onload = __semio__onload; gc.defer = true;
        gc.src = 'https://integration.graphcomment.com/gc_graphlogin.js?' + Date.now();
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(gc);
      })();
    </script>
</body>
</html>
